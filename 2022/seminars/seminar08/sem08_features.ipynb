{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Семинар\n",
    "\n",
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель этого семинара — продемонстрировать несколько способов оценки важности признаков и их использования для отбора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.testing as np_testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAGIC – Major Atmospheric Gamma Imaging Cherenkov Telescope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC (Major Atmospheric Gamma Imaging Cherenkov) - это система, состоящая из двух черенковских телескопов диаметром 17 м. Они предназначены для наблюдения гамма-лучей от галактических и внегалактических источников в диапазоне очень высоких энергий (от 30 ГэВ до 100 ТэВ). \n",
    "\n",
    "Телескопами MAGIC в настоящее время управляют около 165 астрофизиков из 24 организаций и консорциумов из 12 стран. MAGIC позволил открыть и исследовать новые классы источников гамма-излучения, таких как, например, пульсары и гамма-всплески (GRB).\n",
    "\n",
    "<center><img src=\"img/magic1.jpg\" width=\"1000\"></center>\n",
    "\n",
    "Источник: https://magic.mpp.mpg.de/\n",
    "\n",
    "Youtube video: https://youtu.be/mjcDSR2vSU8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частицы из космоса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Космические частицы, $\\gamma$-кванты (фотоны) и адроны (протоны), взаимодействуют с атмосферой и порождают ливни вторичных частиц. Двигаясь с околосветовой скоростью, эти частицы излучают Черенковское излучение. Телескопы фотографируют это излучение. По фотографиям можно определить тип частицы из космоса: фотон или протон.\n",
    "\n",
    "<center><img src=\"img/shower.jpg\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фотографии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача атмосферного черенковского телескопа - получить изображение ливня путем измерения черенковского света от частиц ливня. Это изображение представляет собой геометрическую проекцию ливня на детектор. Для анализа этих изображений были введены параметры изображения или так называемые параметры Хилласа. Есть два вида параметров изображения: параметры формы и параметры ориентации. (Источник: http://ihp-lx.ethz.ch/Stamet/magic/parameters.html)\n",
    "\n",
    "<center><img src=\"img/geo.jpg\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фотоны vs адронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения для $\\gamma$-квантов (фотонов) и адронов (протонов) отличаются по форме кластеров. Астрономы используют модели машинного обучения для классификации этих изображений. Для обучения моделей ученые искусственно генерируют такие изображения для каждого типа частиц с помощью сложных физических симуляторов.\n",
    "\n",
    "\n",
    "<center><img src=\"img/gamma_p.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "UCI MAGIC dataset: https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features description:\n",
    "- **Length:** continuous # major axis of ellipse [mm]\n",
    "- **Width:** continuous # minor axis of ellipse [mm]\n",
    "- **Size:** continuous # 10-log of sum of content of all pixels [in #phot]\n",
    "- **Conc:** continuous # ratio of sum of two highest pixels over fSize [ratio]\n",
    "- **Conc1:** continuous # ratio of highest pixel over fSize [ratio]\n",
    "- **Asym:** continuous # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- **M3Long:** continuous # 3rd root of third moment along major axis [mm]\n",
    "- **M3Trans:** continuous # 3rd root of third moment along minor axis [mm]\n",
    "- **Alpha:** continuous # angle of major axis with vector to origin [deg]\n",
    "- **Dist:** continuous # distance from origin to center of ellipse [mm]\n",
    "- **Label:** g,h # gamma (signal), hadron (background)\n",
    "\n",
    "g = gamma (signal): 12332 \\\n",
    "h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hse-ds/ml-hse-nes/main/2022/seminars/seminar08/data/MAGIC/magic04.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f_names = np.array([\"Length\", \"Width\", \"Size\", \"Conc\", \"Conc1\", \"Asym\", \"M3Long\", \"M3Trans\", \"Alpha\", \"Dist\"])\n",
    "\n",
    "data = pd.read_csv(\"magic04.data\", header=None, names=list(f_names)+[\"Label\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# prepare a matrix of input features\n",
    "X = data[f_names].values\n",
    "\n",
    "# prepare a vector of true labels\n",
    "y = 1 * (data['Label'].values == \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test subsamples to fit and test classifiers\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=11, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting based feature importances\n",
    "\n",
    "<center><img src=\"img/tree.png\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $T(f)$ be the set of all nodes which use feature $f$ to make split. Then, feature importance $Imp(f)$ of $f$:\n",
    "\n",
    "$$\n",
    "Imp(f) = \\sum_{t \\in T(f)} n_t \\Delta I(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta I(t) = I(t) - \\sum_{c \\in children} \\frac{n_c}{n_t} I(c)\n",
    "$$\n",
    "\n",
    "where\n",
    "- $n_{t}$ - number of objects in node $t$;\n",
    "- $I(t)$ – impurity function (gini, cross-entropy, MSE) value for the node.\n",
    "\n",
    "Feature importances estimated by each tree in an ensemble are averaged over all trees in this ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# this function will be used just to plot feature importances\n",
    "\n",
    "def plot_feature_importances(f_imps, f_names, title=\"\"):\n",
    "    f_imps = np.array(f_imps)\n",
    "    f_names = np.array(f_names)\n",
    "    sort_inds = np.argsort(f_imps)\n",
    "    yy = np.arange(len(f_imps)).astype(int)\n",
    "    plt.barh(yy, f_imps[sort_inds])\n",
    "    plt.yticks(yy, f_names[sort_inds], size=14)\n",
    "    plt.xticks(size=14)\n",
    "    plt.xlabel(\"Feature importance\", size=14)\n",
    "    plt.title(title, size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import quality metrics and GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# define a classifier\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=11)\n",
    "\n",
    "# fit it using the train subsample\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# get predictions for the test subsample\n",
    "y_test_proba = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# compute roc auc score on the test\n",
    "roc_auc_gb = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "print(\"Test ROC AUC: \", roc_auc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get feature imporatnces\n",
    "f_imps_gb = gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the feature importances\n",
    "plot_feature_importances(f_imps_gb, f_names, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model based feature importances\n",
    "\n",
    "Consider a linear model with regularization ($L_1$ or $L_2$ penalty):\n",
    "\n",
    "$$\n",
    "\\hat{y}=w_0 + w_1 f_1+ w_2 f_2 + ... + w_k f_k\n",
    "$$\n",
    "\n",
    "If features are normalized (have the same ranges), feature importance $Imp(f_i)$ of $f_i$ is equal to:\n",
    "\n",
    "$$\n",
    "Imp(f_i) = | w_i |\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Estimate feature importacnes using linear model as it is described above.\n",
    "\n",
    "**Hints:** use `StandardScaler()` to normalize feature values. Also, use `LogisticRegression(solver='liblinear', penalty='l2', C=C, random_state=11)` for the linear model. To get values of the model coefficients use `<model>.coef_[0]` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "ba9090_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_feature_imp_with_lin_mod(X_train, y_train, C=1.0):\n",
    "    \"\"\"\n",
    "    Estimate feature importances using linear model with regularization.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train: numpy.ndarray\n",
    "        Object features matrix.\n",
    "    y_train: numpy.array\n",
    "        Vector of true class labels.\n",
    "    C: float\n",
    "        Inverse of regularization strength; must be a positive float.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    f_imps_lin: numpy.array\n",
    "        Estimated feature importances.\n",
    "    \"\"\"\n",
    "\n",
    "    # normalize feature values\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_ss = ss.transform(X_train)\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    ...\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return f_imps_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f_imps_lin = get_feature_imp_with_lin_mod(X_train, y_train, C=1.)\n",
    "f_imps_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "array([1.23276898, 0.08849417, 0.31007411, 0.07866152, 0.69042639,\n",
    "       0.01030818, 0.31858178, 0.01445776, 1.20855327, 0.0711564 ])\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "ba9090",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "actual  = f_imps_lin\n",
    "desired = np.array([1.23276898, 0.08849417, 0.31007411, 0.07866152, 0.69042639,\n",
    "                    0.01030818, 0.31858178, 0.01445776, 1.20855327, 0.0711564 ])\n",
    "np_testing.assert_almost_equal(actual, desired, decimal=3)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the feature importances\n",
    "plot_feature_importances(f_imps_lin, f_names, \"Linear model\")\n",
    "plot_feature_importances(f_imps_gb, f_names, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have any ideas why the feature importances are so different for these two models? Let's compare quality of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# normalize feature values\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_ss = ss.transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)\n",
    "\n",
    "# fit a linear model with regularization\n",
    "linclf = LogisticRegression(solver='liblinear', penalty='l2', C=1.0, random_state=11)\n",
    "linclf.fit(X_train_ss, y_train)\n",
    "\n",
    "# get predictions for the test subsample\n",
    "y_test_proba = linclf.predict_proba(X_test_ss)[:, 1]\n",
    "\n",
    "# compute roc auc score on the test\n",
    "roc_auc_lin = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"Test ROC AUC (GB)    : \", roc_auc_gb)\n",
    "print(\"Test ROC AUC (LogReg): \", roc_auc_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General method\n",
    "\n",
    "<center><img src=\"img/general.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "- Train your model\n",
    "- Calculate quality measure $Q_0$ on the test set\n",
    "- For a feature $f$:\n",
    " - Replace given values with random values from the same distribution (perform random shuffling)\n",
    " - Calculate quality measure $Q_f$ on the test set\n",
    " - Estimate feature importance: $Imp(f)=Q_0 - Q_f$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Estimate feature importances using general algorithm described above. \n",
    "\n",
    "**Hint:** to shuffle values of one feature use `numpy.random.RandomState(42).shuffle()`, for an example: `X[:, i] = np.random.RandomState(42).shuffle(X[:, i])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define a model that we will use to estimate feature importances\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=11)\n",
    "\n",
    "# fit the model on the train sample\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "1df626_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_imp_general(X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Estimate feature importances using linear model with regularization.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_test: numpy.ndarray\n",
    "        Object features matrix.\n",
    "    y_test: numpy.array\n",
    "        Vector of true class labels.\n",
    "    model: object\n",
    "        A classifier fitted on the train sample\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    f_imps_gen: numpy.array\n",
    "        Estimated feature importances.\n",
    "    \"\"\"\n",
    "    \n",
    "    # define a list for the feature importances\n",
    "    f_imps_gen = []\n",
    "\n",
    "    # calculate the base quality value according to the algorithm\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    q_0 = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    # for each feature in the sample estimate its importance\n",
    "    for i in range(X_test.shape[1]):\n",
    "        \n",
    "        # do not forget to make a copy of X_test!\n",
    "        X_test_copy = X_test.copy()\n",
    "        \n",
    "        # shuffle values of the i-th feature\n",
    "        ### BEGIN SOLUTION\n",
    "        ...\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # calculate quality metric value\n",
    "        X_test_copy = np.nan_to_num(X_test_copy)\n",
    "        y_test_proba = model.predict_proba(X_test_copy)[:, 1]\n",
    "        q_f = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        # estimate importance of the feature\n",
    "        imp = q_0 - q_f\n",
    "        f_imps_gen.append(imp)\n",
    "        \n",
    "    return np.array(f_imps_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f_imps_gen = get_feature_imp_general(X_test, y_test, model)\n",
    "f_imps_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output (approximately):\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "array([0.04537013, 0.06596446, 0.08269023, 0.00817734, 0.00350842,\n",
    "       0.00091059, 0.00249184, 0.00053674, 0.11450679, 0.09304359])\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "1df626",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "actual  = f_imps_gen\n",
    "desired = np.array([0.04537013, 0.06596446, 0.08269023, 0.00817734, 0.00350842,\n",
    "                    0.00091059, 0.00249184, 0.00053674, 0.11450679, 0.09304359])\n",
    "np_testing.assert_almost_equal(actual, desired, decimal=2)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(f_imps_gen, f_names, \"General\")\n",
    "plot_feature_importances(f_imps_gb, f_names, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive feature elimination\n",
    "\n",
    "- Train a model on the full set of features\n",
    "- Estimate feature importance (based on the model)\n",
    "- Remove the least important feature\n",
    "- Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Implement recursive feature elimination using `model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=11)` as a model.\n",
    "\n",
    "**Hint:** use feature importances estimated by the model `model.feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "70c60f_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# make copies for further steps\n",
    "X_train_curr = X_train.copy()\n",
    "X_test_curr  = X_test.copy()\n",
    "f_names_curr = f_names.copy()\n",
    "\n",
    "# for storing roc auc scores\n",
    "roc_auc_scores = []\n",
    "\n",
    "# eliminate feature by feature\n",
    "for i in range(X.shape[1]):\n",
    "    \n",
    "    print(\"Features: \", f_names_curr)\n",
    "    \n",
    "    # 1. fit the model using current set of festures\n",
    "    # 2. get feature importances\n",
    "    ### BEGIN SOLUTION\n",
    "    ...\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    # compute roc auc of the model\n",
    "    y_test_proba = model.predict_proba(X_test_curr)[:, 1]\n",
    "    auc = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    # print and store it\n",
    "    auc = np.round(auc, 4)\n",
    "    print(\"ROC AUC: \", auc)\n",
    "    roc_auc_scores.append(auc)\n",
    "\n",
    "    # remove feature with the least importance\n",
    "    X_train_curr = X_train_curr[:, f_imps > f_imps.min()]\n",
    "    X_test_curr  = X_test_curr[:, f_imps > f_imps.min()]\n",
    "    f_names_curr = f_names_curr[f_imps > f_imps.min()]\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(\"Output: \", roc_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "[0.9235, 0.9232, 0.9229, 0.9218, 0.9187, 0.9153, 0.9113, 0.8862, 0.8666, 0.7823]\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "70c60f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "actual  = roc_auc_scores\n",
    "desired = [0.9235, 0.9232, 0.9229, 0.9218, 0.9187, 0.9153, 0.9113, 0.8862, 0.8666, 0.7823]\n",
    "np_testing.assert_almost_equal(actual, desired, decimal=3)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nf = np.arange(1, len(roc_auc_scores)+1)[::-1]\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(nf, roc_auc_scores, linewidth=3)\n",
    "plt.scatter(nf, roc_auc_scores, linewidth=3)\n",
    "\n",
    "plt.xlabel(\"Number of features\", size=16)\n",
    "plt.ylabel(\"ROC AUC\", size=16)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.grid(b=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
